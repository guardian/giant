play {
  # 30 minute JWT expiry
  http.session {
    maxAge = 1800000
    jwtResponseName = "X-Offer-Authorization"
  }

  # When updating this value, also update MAX_FILE_UPLOAD_SIZE_MBYTES in UploadFiles.tsx
  http.parser.maxDiskBuffer = 300MB

  # Disable CSRF if there is an Authorization header
  filters {
    csrf.header.bypassHeaders = {
      Authorization: "*"
    }

    headers.allowActionSpecificHeaders = true
  }

  application {
    name = "pfi"
    loader = AppLoader
  }

  assets.urlPrefix = ""
  assets.cache."/public/index.html" = "no-cache"

  i18n.langs = [ "en", "fr" ]
  # TODO MRB: this is here because PDFjs uses inline styles, fonts and blobby images. Can we remove or harden?
  # TODO MRB: We can remove font-src when we get rid of Semantic UI (it @imports a Google font)
  filters.headers.contentSecurityPolicy = "font-src 'self' default-src blob: data: 'self' 'unsafe-inline'"

  pekko.actor-system = "pfi"
}

pekko {
    actor.provider = "cluster"

      remote {
        log-remote-lifecycle-events = off

        artery {
          canonical {
            hostname = "localhost"
            port = 1234
          }
        }
      }
    cluster {
            metrics.enabled = off
            seed-nodes = ["pekko://pfi@localhost:1234"]
            # For development - in production you probably want to set this to the number of processing nodes to avoid
            # inadvertent work re-distribution
            min-nr-of-members = 1
    }
}

# Execution context for batch and background tasks
work-context {
  fork-join-executor {
    parallelism-factor = 25.0
    parallelism-max = 200
  }
}

# Execution context for blocking queries to the Neo4J database
neo4j-context {
  fork-join-executor {
    parallelism-factor = 25.0
    parallelism-max = 200
  }
}

# Execution context for blocking queries to S3
s3-context {
  fork-join-executor {
    parallelism-factor = 25.0
    parallelism-max = 200
  }
}

# Execution context for ingesting content
ingestion-context {
  executor = "thread-pool-executor"
  throughput = 1
  thread-pool-executor {
    fixed-pool-size = 10
  }
}

app {
  // This option merely hides the button and is not a security feature to prevent the user from downloading if they
  // manually craft requests, because the Preview tab downloads the file to iframe in for preview.
  // The rationale is that hiding the button makes Giant safer for the average user to use on an unmanaged machine
  // as they cannot habitually download each document they find for easier reading.
  hideDownloadButton = false
  readOnly = false
}

auth {
  timeouts {
    maxLoginAge = "8 hours"
    maxVerificationAge = "1 minute"
    maxDownloadAuthAge = "1 minute"
    // higher download timeout on preview to allow for streaming long videos in giant preview mode
    maxDownloadAuthAgePreview = "60 minute"
  }

  enableGenesisFlow = true

  provider = "database"
  database {
    minPasswordLength = 12
    require2FA = false
    totpIssuer = "Giant"
  }
  // the below is not used unless provider is set to "panda" above but here are some useful defaults
  panda {
    bucketName = "pan-domain-auth-settings"
    publicSettingsKey = "local.dev-gutools.co.uk.settings.public"
    cookieName = "gutoolsAuth-assym"
    require2FA = true
    loginUrl = "https://login.local.dev-gutools.co.uk/login"
    aws {
      region = "eu-west-1"
      profile = "investigations"
    }
  }
}

worker {
  # How often will each worker check to see if there is new work available
  interval = "30 seconds"
  # How often will the frontends check to see if workers need to be created/removed
  controlInterval = "30 seconds"
  # How long will the frontends wait since the last worker creation/termination before performing another
  controlCooldown = "5 minutes"
  enabled = true
  workspace = "/tmp"
  useExternalExtractors = true
}

neo4j {
  url = "bolt://localhost:7687"
  user = "neo4j"
  password = "bob"
  queryLogging {
    slowQueryThreshold = "100 milliseconds"
    logAllQueries = false
  }
}

postgres {
  host = "localhost"
  port = 8432
  username = "giant_master"
  password = "giant"
}

s3 {
  buckets {
    ingestion = "ingest-data"
    deadLetter = "ingest-data-dead-letter"
    collections = "data"
    preview = "preview"
    transcription = "transcription-output-data"
    remoteIngestion = "remote-ingest-data"
  }

  region = "us-east-1"
  endpoint = "http://127.0.0.1:9090"
  accessKey = "minio-user"
  secretKey = "reallyverysecret"
}

elasticsearch {
  hosts = ["http://127.0.0.1:9200"]
  indexName = "pfi"
  tableRowIndexName = "pfi-rows"
  eventIndexName = "pfi-events",
  pageIndexNamePrefix = "pfi-pages"
  shards = 5
}

ingestion {
  chunkSize = 1048576
  inMemoryThreshold = 5242880
  batchSize = 100
  fingerprintFiles = true
  # TODO: setting this to /tmp/pfi caused Amy's antivirus to lock up the whole of PFI. Why? Should we use another folder?
  scratchPath = "/tmp/pfi"
}

preview {
  workspace = "/tmp/pfi-preview"
  libreOfficeBinary = "soffice"
  wkhtmltopdfBinary = "wkhtmltopdf"
  annotateSearchHighlightsDirectlyOnPage = false
}

ocr {
  defaultEngine = "OCRmyPDF"
  dpi = 300
  tesseract {
    pageSegmentationMode = 1
    # Tess3 -> Cube only, Tess4 -> LSTM only
    engineMode = 3
  }
}

transcribe {
    whisperModelFilename = "ggml-base.bin"
    transcriptionServiceQueueUrl = "http://localhost:4566/000000000000/transcription-service-gpu-task-queue-DEV.fifo"
    transcriptionOutputQueueUrl = "http://localhost:4566/000000000000/giant-output-queue-DEV.fifo"
    transcriptionOutputDeadLetterQueueUrl = "http://localhost:4566/000000000000/giant-output-dead-letter-queue-DEV.fifo"
}

remoteIngest {
  taskTopicArn = "arn:aws:sns:eu-west-1:000000000000:transcription-service-combined-task-topic-DEV"
  outputDeadLetterQueueUrl = "http://localhost:4566/000000000000/giant-media-download-output-dead-letter-queue-DEV"
  outputQueueUrl = "http://localhost:4566/000000000000/giant-media-download-output-queue-DEV"
}

sqs {
    region = "eu-west-1",
    endpoint = "http://localhost:4566"
}

# This will overwrite some settings from above
include "site.conf"
